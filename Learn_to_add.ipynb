{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learn-to-add.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMnrUyoD5HzVwLajLO256sd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enrico-atzeni/pytorch-simple-add-net/blob/main/Learn_to_add.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdPJZX0pHZh8"
      },
      "source": [
        "# Lets import some libraries \n",
        "import torch # PyTorch \n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv0uo0LzaA4q",
        "outputId": "596af6b0-66cc-4ab7-aa2b-37c91abe1afe"
      },
      "source": [
        "# allow reproducibility for find better model and window and horizon size\n",
        "#seed = random.randrange(10000000)\n",
        "# this is a good seed, extracted from some random seed consecutive tests\n",
        "seed = 5787229\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "print (seed)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5787229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS_2jdpiIvgS"
      },
      "source": [
        "# Define Model\n",
        "class MaiModel(nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super(MaiModel, self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(input_size, output_size)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    y = self.fc1(x)\n",
        "    return y"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy94SkDsKCWf"
      },
      "source": [
        "# Define the dataset\n",
        "\n",
        "# shape: 10,2\n",
        "x_values = [[random.randrange(10), random.randrange(10)] for i in range(10)]\n",
        "\n",
        "# use whole dataset as batch of 10 items\n",
        "x_train = np.array(x_values, dtype=np.float32)\n",
        "\n",
        "y_values = [[sum(i)] for i in x_values]\n",
        "\n",
        "# use whole dataset as batch of len(x_values) items\n",
        "y_train = np.array(y_values, dtype=np.float32)\n",
        "\n",
        "input_size = 2\n"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vXzqlDJVUJG"
      },
      "source": [
        "# DATASET LINEAR EASY\n",
        "if False:\n",
        "  x_values = [i for i in range(11)]\n",
        "  x_train = np.array(x_values, dtype=np.float32)\n",
        "  x_train = x_train.reshape(-1, 1)\n",
        "\n",
        "  y_values = [2*i+1 for i in x_values]\n",
        "  y_train = np.array(y_values, dtype=np.float32)\n",
        "  y_train = y_train.reshape(-1, 1)\n",
        "\n",
        "  input_size = 1"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMeDh6NaKPLx",
        "outputId": "216a004c-22ca-4364-d33a-7e5adf906ab4"
      },
      "source": [
        "# print dataset for debug\n",
        "print (\"This is the dataset\")\n",
        "for i in range(len(x_values)):\n",
        "  print ('%d + %d = %d' % (int(x_values[i][0]), int(x_values[i][1]), int(y_values[i][0])))\n",
        "\n",
        "print (\" \")\n",
        "print (\"X shape is %s\" % (str(torch.tensor(x_values).shape)))\n",
        "print (\"Y shape is %s\" % (str(torch.tensor(y_values).shape)))\n",
        "\n",
        "#print (\"X is\")\n",
        "#print(torch.tensor(x_values))\n"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the dataset\n",
            "9 + 9 = 18\n",
            "2 + 1 = 3\n",
            "9 + 2 = 11\n",
            "5 + 9 = 14\n",
            "3 + 9 = 12\n",
            "4 + 6 = 10\n",
            "6 + 5 = 11\n",
            "6 + 9 = 15\n",
            "3 + 9 = 12\n",
            "1 + 0 = 1\n",
            " \n",
            "X shape is torch.Size([10, 2])\n",
            "Y shape is torch.Size([10, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtXG8ycGMDXT"
      },
      "source": [
        "# train config\n",
        "inputDim = input_size\n",
        "outputDim = 1\n",
        "learningRate = 1e-4 \n",
        "epochs = 5000\n",
        "\n",
        "##### For GPU #######\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = MaiModel(inputDim, outputDim)\n",
        "\n",
        "# convert into GPU or CPU\n",
        "model.to(device)\n",
        "\n",
        "criterion = torch.nn.MSELoss() \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmlbc4D7MTnb",
        "outputId": "29616129-dbcc-43d0-c9cf-c3332a29884c"
      },
      "source": [
        "# TRAIN\n",
        "for epoch in range(epochs):\n",
        "  inputs = Variable(torch.from_numpy(x_train))\n",
        "  labels = Variable(torch.from_numpy(y_train))\n",
        "  \n",
        "  # convert into GPU or CPU\n",
        "  inputs.to(device)\n",
        "  labels.to(device)\n",
        "  \n",
        "  # inputs must be flattened from 10x2 to 20\n",
        "  # inputs = inputs.view(1, -1)\n",
        "  #print(inputs.shape)\n",
        "  #print(inputs)\n",
        "  #print(labels.shape)\n",
        "  #print(labels)\n",
        "\n",
        "  # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # get output from the model, given the inputs\n",
        "  outputs = model(inputs)\n",
        "\n",
        "  # get loss for the predicted output\n",
        "  loss = criterion(outputs, labels)\n",
        "  # print(loss.item())\n",
        "  # get gradients w.r.t to parameters\n",
        "  loss.backward()\n",
        "\n",
        "  # update parameters\n",
        "  optimizer.step()\n",
        "\n",
        "  # print loss only 10 times\n",
        "  if epoch % math.ceil(epochs*0.1) == 0:\n",
        "    print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
        "\n",
        "print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
        "print (\"FINISHED! -------\")"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0, loss 169.24266052246094\n",
            "epoch 500, loss 0.078524149954319\n",
            "epoch 1000, loss 0.02283766120672226\n",
            "epoch 1500, loss 0.007562672253698111\n",
            "epoch 2000, loss 0.0033349147997796535\n",
            "epoch 2500, loss 0.002135149436071515\n",
            "epoch 3000, loss 0.001766358269378543\n",
            "epoch 3500, loss 0.0016265257727354765\n",
            "epoch 4000, loss 0.0015507168136537075\n",
            "epoch 4500, loss 0.0014936631778255105\n",
            "epoch 4999, loss 0.0014430712908506393\n",
            "FINISHED! -------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6ilKF-bXBZi"
      },
      "source": [
        "Good! Now let's validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8RVtLbTXGW-",
        "outputId": "c4c74a9b-9c08-4021-f80b-8aa521482460"
      },
      "source": [
        "validation_dataset = [\n",
        "                      [10, 3],\n",
        "                      [99, 2],\n",
        "                      [7,8]\n",
        "                      ]\n",
        "val_numpy = np.array(validation_dataset, dtype=np.float32)\n",
        "val = Variable(torch.from_numpy(val_numpy).to(device))\n",
        "\n",
        "with torch.no_grad(): # we don't need gradients in the testing phase\n",
        "    predicted = model(val).data.numpy()\n",
        "    print(predicted)\n"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 13.013483]\n",
            " [101.79377 ]\n",
            " [ 15.016182]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}